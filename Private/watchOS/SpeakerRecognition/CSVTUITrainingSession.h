//
//   Generated by https://github.com/blacktop/ipsw (Version: 3.1.454, BuildTime: 2024-02-08T22:07:34Z)
//
//    - LC_BUILD_VERSION:  Platform: watchOSSimulator, MinOS: 10.2, SDK: 10.2, Tool: ld (902.8)
//    - LC_SOURCE_VERSION: 3302.21.3.0.0
//
#ifndef CSVTUITrainingSession_h
#define CSVTUITrainingSession_h
@import Foundation;

#include "CSVTUIAudioSession-Protocol.h"
#include "CSVTUIAudioSessionDelegate-Protocol.h"
#include "CSVTUIEndPointDelegate-Protocol.h"
#include "CSVTUIKeywordDetector.h"
#include "CSVTUITrainingSessionDelegate-Protocol.h"
#include "SFSpeechRecognitionTaskDelegate-Protocol.h"

@class CSAudioZeroCounter, CSVTUITrainingSessionHelper, NSDictionary, NSMutableArray, NSString, NSTimer, NSUUID, SFSpeechAudioBufferRecognitionRequest, SFSpeechRecognitionTask, SFSpeechRecognizer;
@protocol OS_dispatch_queue;

@interface CSVTUITrainingSession : NSObject<SFSpeechRecognitionTaskDelegate, CSVTUIAudioSessionDelegate, CSVTUIEndPointDelegate> {
  /* instance variables */
  long long _status;
  long long _utteranceId;
  long long _sessionNumber;
  NSString *_locale;
  NSUUID *_mhUUID;
  NSString *_vtAssetConfigVersion;
  CSVTUIKeywordDetector *_keywordDetector;
  NSObject<CSVTUIAudioSession> *_audioSession;
  SFSpeechRecognizer *_speechRecognizer;
  SFSpeechAudioBufferRecognitionRequest *_speechRecognitionRequest;
  SFSpeechRecognitionTask *_speechRecognitionTask;
  NSTimer *_masterTimer;
  NSMutableArray *_pcmBufArray;
  BOOL _resultReported;
  BOOL _sessionProcess;
  BOOL _sessionSuspended;
  BOOL _ASRErrorOccured;
  NSObject<CSVTUITrainingSessionDelegate> *_sessionDelegate;
  id /* block */ _trainingCompletion;
  id /* block */ _trainingCompletionWithResult;
  NSObject<OS_dispatch_queue> *_queue;
  CSVTUITrainingSessionHelper *_helper;
  long long _numRequiredTrailingSamples;
  long long _numTrailingSamples;
  CSAudioZeroCounter *_continuousZeroCounter;
}

@property (retain, nonatomic) NSDictionary *voiceTriggerEventInfo;
@property (readonly) unsigned long long hash;
@property (readonly) Class superclass;
@property (readonly, copy) NSString *description;
@property (readonly, copy) NSString *debugDescription;

/* instance methods */
- (id)initWithUtteranceId:(long long)id sessionNumber:(long long)number Locale:(id)locale audioSession:(id)session keywordDetector:(id)detector speechRecognizer:(id)recognizer speechRecognitionRequest:(id)request sessionDelegate:(id)delegate sessionDispatchQueue:(id)queue zeroCounter:(id)counter completion:(id /* block */)completion;
- (id)initWithUtteranceId:(long long)id sessionNumber:(long long)number Locale:(id)locale vtAssetConfigVersion:(id)version audioSession:(id)session keywordDetector:(id)detector speechRecognizer:(id)recognizer speechRecognitionRequest:(id)request sessionDelegate:(id)delegate sessionDispatchQueue:(id)queue mhUUID:(id)uuid zeroCounter:(id)counter completionWithResult:(id /* block */)result;
- (void)startTraining;
- (BOOL)resultAlreadyReported;
- (void)closeSessionWithCompletion:(id /* block */)completion;
- (void)closeSessionWithStatus:(int)status successfully:(BOOL)successfully;
- (void)closeSessionWithStatus:(int)status successfully:(BOOL)successfully complete:(id /* block */)complete;
- (void)closeSessionWithStatus:(int)status successfully:(BOOL)successfully voiceTriggerEventInfo:(id)info completeWithResult:(id /* block */)result;
- (void)suspendTraining;
- (void)resumeTraining;
- (BOOL)setupPhraseSpotter;
- (void)handleAudioInput:(id)input;
- (id)requestTriggeredUtterance:(id)utterance;
- (void)updateMeterAndForward;
- (void)handleAudioBufferForVTWithAudioInput:(id)input withDetectedBlock:(id /* block */)block;
- (void)feedSpeechRecognitionTrailingSamplesWithCompletedBlock:(id /* block */)block;
- (void)feedSpeechRecognitionWithPCMBuffer;
- (void)trimBeginingOfPCMBufferWithVoiceTriggerEventInfo:(id)info;
- (void)computeRequiredTrailingSamples;
- (void)pushAudioInputIntoPCMBuffer:(id)pcmbuffer;
- (id)createAVAudioPCMBufferWithNSData:(id)nsdata;
- (long long)numSamplesInPCMBuffer;
- (void)logTrainingSessionCompleteWithVoiceTriggerEventInfo:(id)info;
- (id)createDigitalZeroReporterWithVoiceTriggerEventInfo:(id)info withSessionStatus:(int)status;
- (int)getTrainingAudioStatusWithVTEI:(id)vtei digitalZeroReporter:(id)reporter;
- (void)audioSessionDidStartRecording:(BOOL)recording error:(id)error;
- (void)audioSessionDidStopRecording:(long long)recording;
- (void)audioSessionRecordBufferAvailable:(id)available;
- (void)audioSessionErrorDidOccur:(id)occur;
- (void)audioSessionUnsupportedAudioRoute;
- (void)didDetectBeginOfSpeech;
- (void)didDetectEndOfSpeech:(long long)speech;
- (void)setupSpeechRecognitionTaskWithVoiceTriggerEventInfo:(id)info;
- (void)finishSpeechRecognitionTask;
- (void)startMasterTimerWithTimeout:(float)timeout;
- (void)handleMasterTimeout:(id)timeout;
- (void)stopMasterTimer;
- (void)speechRecognitionTask:(id)task didHypothesizeTranscription:(id)transcription;
- (void)_registerEndPointTimeout;
@end

#endif /* CSVTUITrainingSession_h */
